# 🚀 LoadLensAI

> 실시간 과적 차량 단속 AI 앱

<br>

## 📖 목차

1. [프로젝트 소개](#-프로젝트-소개)
2. [주요 기능](#-주요-기능)
3. [미리보기](#%EF%B8%8F-미리보기)
4. [사용 기술](#%EF%B8%8F-사용-기술)
5. [설치 및 실행 방법](#%EF%B8%8F-설치-및-실행-방법)
6. [시행착오 및 모델 선정 과정](#-시행착오-및-모델-선정-과정)
7. [한계점 및 개선 방향](#limitations)
   
<br>

## 📌 프로젝트 소개

모바일 온디바이스(On-device) AI를 활용하여 실시간으로 과적 차량을 탐지하는 안드로이드 애플리케이션입니다.
서버 통신 없이 스마트폰 자체 성능만으로 차량의 과적 여부를 판별하여, 단속 현장에서의 효율성과 안전을 높이는 것을 목표로 합니다.

<br>

## ✨ 주요 기능

- **실시간 탐지:** 카메라 프리뷰 화면에서 즉각적인 객체 인식 (30fps 이상)  
- **과적 분류:** 차종과 과적 여부를 결합한 6가지 클래스 판별
- **오프라인 작동:** 인터넷 연결 없이 스마트폰 자체(On-device)에서 독립적으로 수행

<br>

## 🖼️ 미리보기
![KakaoTalk_20251216_230418943](https://github.com/user-attachments/assets/cce4487b-1116-46d3-8578-1a8d2b4b788d)
![KakaoTalk_20251216_230418943_02](https://github.com/user-attachments/assets/5b03497f-7437-4d0b-b241-2cd8fea37ff8)
![KakaoTalk_20251216_230418943_03](https://github.com/user-attachments/assets/2aa1528d-377c-43a0-98ca-236f99fa137c)


<br>

## 🛠️ 사용 기술

- **AI Model:** YOLOv8 (Trained on Custom Dataset -> .tflite Quantization)
- **Mobile:** Android (Kotlin), CameraX
- **Inference:** TensorFlow Lite (GPU Delegate)
- **Environment:** Python 3.9, Android Studio
- **Dataset:** 과적차량 도로 위험 데이터(AI Hub 공개 데이터셋, 수행기관: (주) 에스디엠이앤씨)
<br>

## ⚙️ 설치 및 실행 방법

```bash
# 1. 이 저장소를 클론합니다.
# 2. Android Studio (Iguana 이상)에서 프로젝트를 엽니다.
# 3. Android 기기를 연결하고 실행합니다. (Min SDK: 26)
# 4. Detector의 threshold값을 필요에 맞게 수정하여 사용해도 무방합니다.
```

<br>

## 🚧 시행착오 및 모델 선정 과정

### 1단계: 이미지 분류 접근과 실패
* **시도:** 초기에는 가볍고 성능이 검증된 **EfficientNet**을 사용하여 과적 여부를 판별하는 이진 분류(Binary Classification)를 시도했습니다.
* **현상:** 초기 샘플 데이터 2만 장으로 학습 후, 4,000장의 검증 데이터에서 정확도 95%를 달성하며 가능성을 보였습니다.
  그러나 전체 데이터셋 33만 장으로 학습 규모를 확장하자, 정확도가 **70%대로 급락**하는 현상이 발생했습니다.
* **문제:** "데이터가 늘어나면 성능이 좋아져야 한다"는 일반적인 상식과 달리, 분류 모델이 대용량 데이터의 다양한 변수(배경, 촬영 각도 등)를 소화하지 못하고 **일반화에 실패**했습니다.

### 2단계: 차종별 세분화 시도
* **가설 1:** "2만 장 데이터셋의 품질만 유독 좋았던 것 아닐까?"
    * **검증:** 잘 학습된 2만 장 모델로 4만 장의 검증셋을 테스트했으나 여전히 낮은 성능을 기록. 데이터 양의 문제가 아님을 인지.
* **가설 2:** "소형/중형/대형의 형태 차이가 커서 학습을 방해하는 것 아닐까?"
    * **검증:** 차종을 먼저 분류(소/중/대)하고 각각 과적을 판단하는 파이프라인을 구축했으나, 근본적인 정확도 하락 문제를 해결하지 못했고 추론 속도만 저하됨.
    
### 3단계: 근본 원인 분석
* **분석:** 모델이 이미지의 어느 부분을 보고 판단하는지 확인하기 위해 **Grad-CAM(Class Activation Map) 시각화**를 수행했습니다.
* **발견:**
    * 예상과 달리 모델이 차량의 적재함을 전혀 주목하지 못했습니다.
    * **히트맵의 붉은 영역이 나타나지 않거나**, 배경 전체에 희미하게 퍼지는 현상을 확인했습니다.
    * 즉, 분류 모델이 방대한 배경 노이즈 속에서 **'작은 차량 객체'의 특징을 추출하는 데 완전히 실패**했음을 시각적으로 검증했습니다.
* **결론:** 배경을 잘라내고 차량 영역만 정확히 볼 수 있는 **객체 탐지** 기술로의 전환을 결정했습니다.

### 4단계: YOLOv8 도입 및 최종 해결
* **해결:** 객체의 위치를 찾음과 동시에 클래스를 분류할 수 있는 **YOLOv8** 모델로 기술 스택을 전면 교체했습니다.
* **성과:**
    1.  모델이 정확히 '차량 영역'에만 집중하게 되어 배경 노이즈 문제 해결.
    2.  소형/중형/대형 및 과적 여부를 한 번의 추론으로 처리하여 속도와 정확도 두 마리 토끼를 모두 잡음.

### 5단계: 하이퍼파라미터 튜닝
* **튜닝:** YOLOv8 도입을 결정 후 어느 정도의 성능이 나오는지 우선 기본 설정으로 테스트해 보았으나 YOLOv8이 데이터 셋이 잘 맞은 덕분인지 튜닝 없이도 높은 성능을 기록하여 최종 확정.



<br>
<a id="limitations"></a>

## ⚠️ 한계점 및 개선 방향

### 조명 환경에 따른 인식률 차이
* **현상:** 주간이나 조명이 밝은 실내에서는 높은 정확도를 보이지만, **야간이나 저조도 환경**에서는 인식률이 저하되거나, 과적으로 오인식하는 현상이 발생함.
* **원인 분석:** 학습에 사용된 데이터셋의 대부분이 **주간에 촬영된 이미지**로 구성되어 있어, 야간의 타이어 식별 및 휠 하우스의 음영 처리에 대한 학습이 부족한듯함.
* **해결 방안:** 사용자에게 "충분한 광량이 확보된 곳에서 촬영하세요"라는 가이드 제공.
    * **추후 과제:** 야간 데이터셋을 추가 수집하여 재학습 하거나, 이미지 전처리 단계에서 밝기/대비를 보정하는 알고리즘 도입 필요.
  
<br>
